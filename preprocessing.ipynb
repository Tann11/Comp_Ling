{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "numbers = [\"i\",\"ii\",\"iii\",\"iv\",\"v\",\"vi\",\"vii\",\"viii\",\"ix\",\"x\",\"xi\",\"xii\",\"xiii\",\"xiv\",\"xv\",\"xvi\",\"xvii\",\"xviii\",\"xix\",\"xx\",\"xxi\",\"xxii\",\"xxiii\",\"xxiv\",\"xxv\",\"xxvi\",\"xxvii\",\"xxviii\",\"xxix\",\"xxx\"]\n",
    "stop = []\n",
    "languages = [u\"german\",u\"english\",u\"french\",u\"italian\",u\"dutch\",u\"portuguese\",u\"spanish\"]\n",
    "for el in languages:\n",
    "    st = list(set(stopwords.words(el)))\n",
    "    stop.append(st)\n",
    "print (len(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "udhr_deu_1996.txt\n",
      "udhr_eng.txt\n",
      "udhr_fra.txt\n",
      "udhr_ita.txt\n",
      "udhr_nld.txt\n",
      "udhr_por_PT.txt\n",
      "udhr_spa.txt\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "papki = os.listdir(\"C:\\\\Users\\\\Tatiana\\\\Desktop\\\\docs\")\n",
    "all_langs = []\n",
    "papki = sorted(papki)\n",
    "for x in papki:\n",
    "    print (x)\n",
    "for file in papki:\n",
    "    with open(\"C:\\\\Users\\\\Tatiana\\\\Desktop\\docs\\\\\" + file, \n",
    "          encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        words = []\n",
    "        for line in lines[6:]:\n",
    "            clean_line = re.sub('[\\W\\d_-]+', ' ', line.lower().strip())\n",
    "            line_words = re.split(' +', clean_line)\n",
    "            words += [w for w in line_words if w]\n",
    "    p = codecs.open(file[:-4]+u'_result.txt','w',\"utf-8-sig\")\n",
    "    all_langs.append(words)\n",
    "print (u'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "die\n",
      "universal\n",
      "déclaration\n",
      "il\n",
      "universele\n",
      "declaração\n",
      "declaración\n"
     ]
    }
   ],
   "source": [
    "for x in all_langs:\n",
    "    print (x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dicts = []\n",
    "for i in range(len(all_langs)):\n",
    "    freq = {}\n",
    "    for w in all_langs[i]:\n",
    "        if w not in stop[i] and w not in numbers:\n",
    "            if w not in freq:\n",
    "                freq[w] = 1\n",
    "            else:\n",
    "                freq[w] += 1\n",
    "    wf = list(freq.items())\n",
    "    all_dicts.append(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print (len(all_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('und', 97), ('der', 68), ('die', 53), ('zu', 37), ('auf', 35), ('recht', 32), ('das', 31), ('jeder', 31), ('hat', 31), ('artikel', 30)]\n",
      "[('the', 121), ('and', 106), ('of', 91), ('to', 83), ('in', 43), ('right', 33), ('be', 31), ('article', 30), ('everyone', 30), ('or', 30)]\n",
      "[('de', 134), ('et', 90), ('la', 79), ('à', 63), ('l', 50), ('des', 42), ('droit', 41), ('le', 36), ('a', 32), ('les', 31)]\n",
      "[('di', 91), ('e', 89), ('diritto', 40), ('ogni', 39), ('individuo', 38), ('il', 30), ('della', 30), ('articolo', 30), ('in', 29), ('ha', 29)]\n",
      "[('de', 119), ('van', 108), ('en', 102), ('een', 61), ('het', 54), ('op', 42), ('zijn', 41), ('recht', 39), ('te', 37), ('in', 33)]\n",
      "[('a', 99), ('e', 93), ('de', 87), ('o', 46), ('direito', 42), ('da', 35), ('artigo', 30), ('º', 30), ('ou', 30), ('que', 29)]\n",
      "[('de', 138), ('la', 96), ('y', 94), ('a', 86), ('en', 49), ('el', 48), ('derecho', 42), ('los', 40), ('que', 32), ('tiene', 31)]\n"
     ]
    }
   ],
   "source": [
    "for wf in all_dicts:\n",
    "    #print(wf[:5])\n",
    "    sorted_wf = sorted(wf, key=lambda x: x[1], reverse=True)\n",
    "    print(sorted_wf[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('und', 97), ('der', 68), ('die', 53), ('zu', 37), ('auf', 35), ('recht', 32), ('das', 31), ('jeder', 31), ('hat', 31), ('artikel', 30)]\n",
      "[('the', 121), ('and', 106), ('of', 91), ('to', 83), ('in', 43), ('right', 33), ('be', 31), ('article', 30), ('everyone', 30), ('or', 30)]\n",
      "[('de', 134), ('et', 90), ('la', 79), ('à', 63), ('l', 50), ('des', 42), ('droit', 41), ('le', 36), ('a', 32), ('les', 31)]\n",
      "[('di', 91), ('e', 89), ('diritto', 40), ('ogni', 39), ('individuo', 38), ('il', 30), ('della', 30), ('articolo', 30), ('in', 29), ('ha', 29)]\n",
      "[('de', 119), ('van', 108), ('en', 102), ('een', 61), ('het', 54), ('op', 42), ('zijn', 41), ('recht', 39), ('te', 37), ('in', 33)]\n",
      "[('a', 99), ('e', 93), ('de', 87), ('o', 46), ('direito', 42), ('da', 35), ('artigo', 30), ('º', 30), ('ou', 30), ('que', 29)]\n",
      "[('de', 138), ('la', 96), ('y', 94), ('a', 86), ('en', 49), ('el', 48), ('derecho', 42), ('los', 40), ('que', 32), ('tiene', 31)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_dicts)):\n",
    "    wf = all_dicts[i]\n",
    "    #print(wf[:5])\n",
    "    sorted_wf = sorted(wf, key=lambda x: x[1], reverse=True)\n",
    "    t = codecs.open(languages[i]+u'_WORDS_nostop_result.txt','w',\"utf-8-sig\")\n",
    "    for el in sorted_wf[:300]:\n",
    "        t.write(str(el) + u'\\r\\n')\n",
    "    print(sorted_wf[:10])\n",
    "    t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#если убираем стоп-слова\n",
    "all_ngrams = []\n",
    "for i in range(len(all_langs)):\n",
    "    lang_ngrams = {}\n",
    "    for s in all_langs[i]:\n",
    "        if s not in stop[i]:\n",
    "            n = 3\n",
    "            ngrams = [s[i:i+n] for i in range(len(s)-n+1)]\n",
    "            for ngram in ngrams:\n",
    "                if ngram not in lang_ngrams:\n",
    "                    lang_ngrams[ngram] = 1\n",
    "                else:\n",
    "                    lang_ngrams[ngram] += 1\n",
    "    wf_1 = list(lang_ngrams.items())\n",
    "    all_ngrams.append(wf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если не убираем стоп-слова\n",
    "all_ngrams = []\n",
    "for lang in all_langs:\n",
    "    lang_ngrams = {}\n",
    "    for s in lang:\n",
    "        n = 3\n",
    "        ngrams = [s[i:i+n] for i in range(len(s)-n+1)]\n",
    "        for ngram in ngrams:\n",
    "            if ngram not in lang_ngrams:\n",
    "                lang_ngrams[ngram] = 1\n",
    "            else:\n",
    "                lang_ngrams[ngram] += 1\n",
    "    wf_1 = list(lang_ngrams.items())\n",
    "    all_ngrams.append(wf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(all_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ung', 104), ('cht', 95), ('sch', 90), ('ich', 83), ('ech', 71), ('rec', 68), ('che', 67), ('eit', 64), ('gen', 56), ('ver', 53)]\n",
      "[('ion', 103), ('tio', 89), ('ati', 65), ('igh', 57), ('rig', 56), ('ght', 56), ('ent', 51), ('ver', 44), ('one', 43), ('eve', 40)]\n",
      "[('ion', 109), ('tio', 93), ('ent', 81), ('oit', 69), ('ati', 66), ('roi', 64), ('dro', 63), ('men', 53), ('con', 49), ('tou', 49)]\n",
      "[('ion', 107), ('zio', 89), ('one', 76), ('rit', 72), ('itt', 68), ('dir', 65), ('iri', 65), ('ent', 61), ('ess', 61), ('azi', 60)]\n",
      "[('ing', 106), ('cht', 103), ('der', 82), ('ech', 79), ('ver', 78), ('rec', 74), ('ede', 61), ('ten', 58), ('nde', 56), ('lij', 52)]\n",
      "[('ent', 74), ('ito', 73), ('eit', 71), ('dir', 67), ('ire', 66), ('rei', 65), ('ção', 58), ('ade', 56), ('dad', 54), ('men', 53)]\n",
      "[('ión', 79), ('rec', 76), ('ere', 75), ('der', 73), ('cho', 65), ('ció', 64), ('ech', 64), ('aci', 63), ('ent', 59), ('ona', 51)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_ngrams)):\n",
    "    wf = all_ngrams[i]\n",
    "    #print(wf[:5])\n",
    "    sorted_wf = sorted(wf, key=lambda x: x[1], reverse=True)\n",
    "    t = codecs.open(languages[i]+u'_NGRAMS_3_nostop_result.txt','w',\"utf-8-sig\")\n",
    "    for el in sorted_wf[:300]:\n",
    "        t.write(str(el) + u'\\r\\n')\n",
    "    print(sorted_wf[:10])\n",
    "    t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
