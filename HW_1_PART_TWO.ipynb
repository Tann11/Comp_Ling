{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import numpy\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "numbers = [\"i\",\"ii\",\"iii\",\"iv\",\"v\",\"vi\",\"vii\",\"viii\",\"ix\",\"x\",\"xi\",\"xii\",\"xiii\",\"xiv\",\"xv\",\"xvi\",\"xvii\",\"xviii\",\"xix\",\"xx\",\"xxi\",\"xxii\",\"xxiii\",\"xxiv\",\"xxv\",\"xxvi\",\"xxvii\",\"xxviii\",\"xxix\",\"xxx\"]\n",
    "stop = []\n",
    "languages = [u\"german\",u\"english\",u\"french\",u\"italian\",u\"dutch\",u\"portuguese\",u\"spanish\"]\n",
    "for el in languages:\n",
    "    st = list(set(stopwords.words(el)))\n",
    "    stop.append(st)\n",
    "print (len(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "udhr_deu_1996.txt\n",
      "udhr_eng.txt\n",
      "udhr_fra.txt\n",
      "udhr_ita.txt\n",
      "udhr_nld.txt\n",
      "udhr_por_PT.txt\n",
      "udhr_spa.txt\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "papki = os.listdir(\"D:\\\\HSE_2017-2018\\\\NLP\\\\docs\")\n",
    "all_langs = []\n",
    "papki = sorted(papki)\n",
    "for x in papki:\n",
    "    print (x)\n",
    "for file in papki:\n",
    "    with open(\"D:\\\\HSE_2017-2018\\\\NLP\\\\docs\\\\\" + file, \n",
    "          encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        words = []\n",
    "        for line in lines[6:]:\n",
    "            clean_line = re.sub('[\\W\\d_-]+', ' ', line.lower().strip())\n",
    "            line_words = re.split(' +', clean_line)\n",
    "            words += [w for w in line_words if w]\n",
    "    p = codecs.open(file[:-4]+u'_result.txt','w',\"utf-8-sig\")\n",
    "    all_langs.append(words)\n",
    "print (u'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dicts = []\n",
    "for i in range(len(all_langs)):\n",
    "    freq = {}\n",
    "    for w in all_langs[i]:\n",
    "        if w not in stop[i] and w not in numbers:\n",
    "            if w not in freq:\n",
    "                freq[w] = 1\n",
    "            else:\n",
    "                freq[w] += 1\n",
    "    wf = list(freq.items())\n",
    "    all_dicts.append(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('recht', 32)]\n",
      "[('right', 33)]\n",
      "[('droit', 41)]\n",
      "[('diritto', 40)]\n",
      "[('recht', 39)]\n",
      "[('direito', 42)]\n",
      "[('derecho', 42)]\n"
     ]
    }
   ],
   "source": [
    "for wf in all_dicts:\n",
    "    #print(wf[:5])\n",
    "    sorted_wf = sorted(wf, key=lambda x: x[1], reverse=True)\n",
    "    print(sorted_wf[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#если убираем стоп-слова\n",
    "all_ngrams = []\n",
    "for i in range(len(all_langs)):\n",
    "    lang_ngrams = {}\n",
    "    for s in all_langs[i]:\n",
    "        if s not in stop[i]:\n",
    "            n = 3\n",
    "            ngrams = [s[i:i+n] for i in range(len(s)-n+1)]\n",
    "            for ngram in ngrams:\n",
    "                if ngram not in lang_ngrams:\n",
    "                    lang_ngrams[ngram] = 1\n",
    "                else:\n",
    "                    lang_ngrams[ngram] += 1\n",
    "    wf_1 = list(lang_ngrams.items())\n",
    "    all_ngrams.append(wf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ung', 104), ('cht', 95), ('sch', 90), ('ich', 83), ('ech', 71), ('rec', 68), ('che', 67), ('eit', 64), ('gen', 56), ('ver', 53)]\n",
      "[('ion', 103), ('tio', 89), ('ati', 65), ('igh', 57), ('rig', 56), ('ght', 56), ('ent', 51), ('ver', 44), ('one', 43), ('eve', 40)]\n",
      "[('ion', 109), ('tio', 93), ('ent', 81), ('oit', 69), ('ati', 66), ('roi', 64), ('dro', 63), ('men', 53), ('con', 49), ('tou', 49)]\n",
      "[('ion', 107), ('zio', 89), ('one', 76), ('rit', 72), ('itt', 68), ('dir', 65), ('iri', 65), ('ent', 61), ('ess', 61), ('azi', 60)]\n",
      "[('ing', 106), ('cht', 103), ('der', 82), ('ech', 79), ('ver', 78), ('rec', 74), ('ede', 61), ('ten', 58), ('nde', 56), ('lij', 52)]\n",
      "[('ent', 74), ('ito', 73), ('eit', 71), ('dir', 67), ('ire', 66), ('rei', 65), ('ção', 58), ('ade', 56), ('dad', 54), ('men', 53)]\n",
      "[('ión', 79), ('rec', 76), ('ere', 75), ('der', 73), ('cho', 65), ('ció', 64), ('ech', 64), ('aci', 63), ('ent', 59), ('ona', 51)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_ngrams)):\n",
    "    wf = all_ngrams[i]\n",
    "    sorted_wf = sorted(wf, key=lambda x: x[1], reverse=True)\n",
    "    t = codecs.open(languages[i]+u'_NGRAMS_3_nostop_result_UPD.txt','w',\"utf-8-sig\")\n",
    "    for el in sorted_wf[:300]:\n",
    "        t.write(str(el) + u'\\r\\n')\n",
    "    print(sorted_wf[:10])\n",
    "    t.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_words = set([w[0] for w in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "129\n",
      "74\n",
      "87\n",
      "78\n",
      "80\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(len(GE.intersection(GE)))\n",
    "print(len(GE.intersection(DU)))\n",
    "print(len(GE.intersection(SP)))\n",
    "print(len(GE.intersection(EN)))\n",
    "print(len(GE.intersection(FR)))\n",
    "print(len(GE.intersection(IT)))\n",
    "print(len(GE.intersection(PORT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[300, 129,  74,  87,  78,  80,  65],\n",
       "       [129, 300,  68,  92,  78,  75,  66],\n",
       "       [ 74,  68, 300, 136, 127, 146, 185],\n",
       "       [ 87,  92, 136, 300, 150, 147, 133],\n",
       "       [ 78,  78, 127, 150, 300, 125, 124],\n",
       "       [ 80,  75, 146, 147, 125, 300, 137],\n",
       "       [ 65,  66, 185, 133, 124, 137, 300]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ngrammer(f):\n",
    "    arr =[]\n",
    "    f1 = codecs.open(f,'r',\"utf-8-sig\")\n",
    "    for i in f1:\n",
    "        ngram = i[2:5]\n",
    "        arr.append(ngram)\n",
    "    return set(arr)\n",
    "\n",
    "GE = ngrammer('german_NGRAMS_3_nostop_result_UPD.txt')\n",
    "DU = ngrammer('dutch_NGRAMS_3_nostop_result_UPD.txt')\n",
    "SP = ngrammer('spanish_NGRAMS_3_nostop_result_UPD.txt')\n",
    "EN = ngrammer('english_NGRAMS_3_nostop_result_UPD.txt')\n",
    "FR = ngrammer('french_NGRAMS_3_nostop_result_UPD.txt')\n",
    "IT = ngrammer('italian_NGRAMS_3_nostop_result_UPD.txt')\n",
    "PORT = ngrammer('portuguese_NGRAMS_3_nostop_result_UPD.txt') \n",
    "\n",
    "\n",
    "for_matrix = [GE, DU, SP, EN, FR, IT, PORT]\n",
    "\n",
    "#for i in for_matrix:\n",
    "        #for j in for_matrix:\n",
    "        #\"print(len(i.intersection(j)))\"\n",
    "            #res = len(i.intersection(j))\n",
    "            #np.fromfunction(res, (7,7))\n",
    "\n",
    "def intersect(lang):\n",
    "    arr = []\n",
    "    for i in for_matrix:\n",
    "        arr.append(len(lang.intersection(i)))\n",
    "    return(arr)\n",
    "    \n",
    "#for i in intersect(GE):\n",
    "   #print(i)\n",
    "\n",
    "final = np.array([intersect(GE), intersect(DU), intersect(SP), intersect(EN), intersect(FR), intersect(IT), intersect(PORT)])\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German</th>\n",
       "      <th>Dutch</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Portuguese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>German</th>\n",
       "      <td>300</td>\n",
       "      <td>129</td>\n",
       "      <td>74</td>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dutch</th>\n",
       "      <td>129</td>\n",
       "      <td>300</td>\n",
       "      <td>68</td>\n",
       "      <td>92</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>74</td>\n",
       "      <td>68</td>\n",
       "      <td>300</td>\n",
       "      <td>136</td>\n",
       "      <td>127</td>\n",
       "      <td>146</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engish</th>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>136</td>\n",
       "      <td>300</td>\n",
       "      <td>150</td>\n",
       "      <td>147</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>French</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>127</td>\n",
       "      <td>150</td>\n",
       "      <td>300</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italian</th>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>125</td>\n",
       "      <td>300</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portuguese</th>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>185</td>\n",
       "      <td>133</td>\n",
       "      <td>124</td>\n",
       "      <td>137</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            German  Dutch  Spanish  English  French  Italian  Portuguese\n",
       "German         300    129       74       87      78       80          65\n",
       "Dutch          129    300       68       92      78       75          66\n",
       "Spanish         74     68      300      136     127      146         185\n",
       "Engish          87     92      136      300     150      147         133\n",
       "French          78     78      127      150     300      125         124\n",
       "Italian         80     75      146      147     125      300         137\n",
       "Portuguese      65     66      185      133     124      137         300"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_items([('German', intersect(GE)), ('Dutch', intersect(DU)), ('Spanish', intersect(SP)),\n",
    "                         ('Engish', intersect(EN)), ('French', intersect(FR)), ('Italian', intersect(IT)), \n",
    "                         ('Portuguese', intersect(PORT)) ],\n",
    "          orient='index', columns=['German', 'Dutch', 'Spanish', 'English', 'French', 'Italian', 'Portuguese'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В близкорородственных языках пересечений больше, чем между языками разных групп"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
